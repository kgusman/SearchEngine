Title       : The Reliability of Survey Data
Type        : Award
NSF Org     : SES 
Latest
Amendment
Date        : September 12,  1997 
File        : a9710403

Award Number: 9710403
Award Instr.: Standard Grant                               
Prgm Manager: Patricia White                          
	      SES  DIVN OF SOCIAL AND ECONOMIC SCIENCES    
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : September 15,  1997 
Expires     : August 31,  2000     (Estimated)
Expected
Total Amt.  : $129407             (Estimated)
Investigator: Duane Alwin dalwin@pop.psu.edu  (Principal Investigator current)
Sponsor     : University of Michigan
	      3003 S State St. RM 1062
	      Ann Arbor, MI  481091274    734/764-1817

NSF Program : 1331      SOCIOLOGY
Fld Applictn: 0000099   Other Applications NEC                  
              0116000   Human Subjects                          
Program Ref : 0000,OTHR,
Abstract    :
               This is a methodological study of the reliability of survey data.  Given the
              heavy reliance of the social, economic and behavioral sciences on the results
              of surveys and other question-answer methods of gathering important data, it is
              essential to know the overall reliability or dependability of survey results.
              This project will conduct a systematic analysis of the measurement of
              reliability of responses to survey questions, to better understand the nature
              of survey data and the processes by which they are generated. A secondary goal
              is to make practical recommendations about the attributes of survey questions
              that will maximize their reliability of measurement.      The unit of analysis
              is the survey question. The project will assemble a database for survey
              questions, consisting of question-level information on reliability and question
              characteristics for more than 1,000 variables from six large-scale panel
              surveys of national populations in the U.S., which will provide a basis for
              testing several hypotheses regarding variation in reliability of survey
              measurement. The survey interview is conceived of as a method for gathering
              information, which involves a number of critical elements --comprehension,
              accessibility, retrieval, and communication -- that play a role in affecting
              the quality of data. These factors are theorized to contribute to measurement
              errors in a way that can be linked to the survey question and the context of
              measurement. In contrast to other approaches, this research will estimate the
              reliability of single survey questions, and will examine variations in
              reliability as a function of differences in the method of analysis.
              Specifically, the project will compare estimates of reliability based on
              structural equation models with those based on Rasch models based on
              item-response theory, and will explore categoric data approaches to the same
              set of issues.     The approach taken relies on multi-wave panel data for the
              estimation of reliability. Six such panel studies from probabi lity samples of
              the U.S. will be used: 1) the 1956-58-60 National Election Study (NES) panel,
              2) the 1972-74-76 NES panel, 3) the 1990-91-92 NES panel, 4) the 1992-93-94 NES
              panel, 5) the 1986-94 Americans' Changing Lives (ACL) panel study, and 6) the
              Study of American Families (SAF) 1980-85-93 three-wave panel on young adults
              and more than 5 waves on their mothers, dating to 1961.      The research will
              address the following question areas:  a) How reliable are survey data in
              general?  b) Does reliability of measurement depend on the nature of the
              content being measured?  In particular, is factual information gathered more
              precisely than attitudinal and/or other subjective data?  And, do types of
              nonfactual questions (attitudes, beliefs and self-assessments) differ in
              reliability?  c) Does reliability of measurement vary as a function of the
              properties of the approach to measurement?  In the case of factual data, are
              proxy reports as reliable as self-reports?  How reliable are interviewer
              observations?  d) Does the nature of the question affect the quality of data? 
              For example, in attitude measurement, how is reliability affected by the nature
              of the question-phrasing, the number of response categories, the extent of
              verbal labeling, and other properties of the response format?   e) With respect
              to attitude and other subjective data, is reliability affected by changing the
              context of the questions?      The research proposes to assess questions in
              these areas within the framework of a set of working hypotheses derived from
              theory and research experience on the sources of measurement errors. Simply
              put, the analysis will focus on explaining variation in reliability due to
              these several factors.     Assembling information on measurement reliability
              from the panel surveys will not only improve knowledge about the strengths and
              weaknesses of particular forms of survey measurement but will also lay the
              groundwork for developing a large-scale data base on survey measurement
              reliability that can addr ess basic issues of data quality in the social,
              economic and behavioral sciences. Increased knowledge regarding these aspects
              of data quality will help evaluate techniques for gathering survey data and
              will improve the quality of survey measurement.
