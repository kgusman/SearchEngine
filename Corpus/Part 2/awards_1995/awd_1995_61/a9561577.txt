Title       : SBIR PHASE I: Automatic Spoken Language Assessment by Telephone
Type        : Award
NSF Org     : DMI 
Latest
Amendment
Date        : January 26,  1996   
File        : a9561577

Award Number: 9561577
Award Instr.: Standard Grant                               
Prgm Manager: Sara B. Nerlove                         
	      DMI  DIV OF DESIGN,MANUFAC & INDUSTRIAL INNOV
	      ENG  DIRECTORATE FOR ENGINEERING             
Start Date  : February 1,  1996   
Expires     : July 31,  1996       (Estimated)
Expected
Total Amt.  : $72544              (Estimated)
Investigator: Jared Bernstein   (Principal Investigator current)
Sponsor     : Entropic Res Lab Inc
	      1040 Noel Drive
	      Menlo Park, CA  94025    202/547-1420

NSF Program : 5371      SMALL BUSINESS PHASE I
Fld Applictn: 0116000   Human Subjects                          
              84        Linguistics                             
Program Ref : 1311,9218,HPCC,
Abstract    :
              9561577  Bernstein   The assessment of spoken language proficiency is essential
              for prospective professions (such as nurses or flight attendants) if they are
              not native speakers of English but need to work in situations where rapid,
              accurate communication is a vital concern.  Assessment of spoken language
              proficiency can also figure in the qualification for many other professions,
              for example for teachers.  This Small Business Innovation Research Phase I
              project will investigate the use of speech recognition in language testing. 
              The guiding objective is to demonstrate techniques that suggest that a feasible
              system for Automatic Spoken Language Assessment by Telephone (ASLAT) can
              produce proficiency scores that are reliable and valid with reference to good
              current tests.  Phase I research will implement a telephone-based system for
              pilot testing various interactions with populations of native and non-native
              speakers.  The immediate objective is to identify several interactive tasks
              that exercise a range of receptive and productive language skills which
              reliably predict a test-taker's level of functional oral proficiency in
              English.  These automated interactions should, first of all, be quite simple
              for native speakers of North American English.  That is, regardless of dialect
              or other demographic characteristics of a native speaker, an ASLAT system
              should return a high score.  At the same time, the ASLAT should distribute
              non-native test-takers over a wide range of scores that reflect the range of
              their functional command of spoken English.    There is good reason to believe
              that advanced speech recognition systems adapted for language assessment and
              operating over the telephone will enable the achievement of the project goal of
              offering valid and reliable spoken language assessments at low cost the user. 
              Current tests of spoken language proficiency are usually administered, scored,
              and reported by human operators.  The labor cost to administer a typical test
              ranges from $10 to $60.  Computer-b ased tests of oral proficiency can probably
              be administered, scored, and reported for between $1 and $2 per test, leaving
              another $3 or $4 per test in margin when tests are offered at $5 per test in
              large volumes.
