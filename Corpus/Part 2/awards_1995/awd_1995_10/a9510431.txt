Title       : Collaborative Research: Perception of 3D Objects in Dynamic Visual Scenes
Type        : Award
NSF Org     : BCS 
Latest
Amendment
Date        : June 11,  1997      
File        : a9510431

Award Number: 9510431
Award Instr.: Continuing grant                             
Prgm Manager: Joseph L. Young                         
	      BCS  DIVISION OF BEHAVIORAL AND COGNITIVE SCI
	      SBE  DIRECT FOR SOCIAL, BEHAV & ECONOMIC SCIE
Start Date  : August 1,  1995     
Expires     : July 31,  1998       (Estimated)
Expected
Total Amt.  : $213350             (Estimated)
Investigator: George J. Andersen ANDERSEN@UCRAC1.UCR.EDU  (Principal Investigator current)
Sponsor     : U of Cal Riverside
	      Office of Research Affairs
	      Riverside, CA  925210217    909/787-5535

NSF Program : 1180      HUMAN COGNITION & PERCEPTION
Fld Applictn: 0116000   Human Subjects                          
              70        Psychology                              
Program Ref : 0000,OTHR,
Abstract    :
              9510431  ANDERSEN    The ability of human observers to perceive and recognize
              objects  in a three-dimensional scene involves several different levels of 
              analysis, including the perception of the overall depth of the  scene, the
              perception of the relative positions of objects or  layout of the scene, and
              the perception of the shapes of objects  within the scene.  At each level of
              analysis the observer may  gain information from a number of different sources,
              some  informative about distances from the observer to parts of the  scene or
              to parts of objects (viewer-centered) and others  informative about depth
              relationships within the scene or within  objects, independent of the position
              of the observer (object-  centered).  Three series of experiments will be
              conducted to  determine how information at each level, scene, layout, and 
              object, and information of each type, viewer-centered and object-  centered,
              combine to provide an integrated perception of the  three-dimensional
              environment.    The first series of experiments will examine the relationship 
              between simulated layout and perceived layout as information for  scene depth
              is manipulated.  The second series of experiments  will assess the effect of
              layout information on the perception of  object properties (relative depth,
              surface orientation, and  overall shape).  The third series of experiments will
              use  selected conditions from the first two series to examine the  combined
              effects of scene depth and layout on the perception of  object properties. 
              Within each of these series, the type of  information (viewer-centered or
              object-centered) for each level  under consideration will be manipulated. 
              Several different cues  for the specification of viewer-centered and
              object-centered  information will be examined including accommodation, linear 
              perspective, motion parallax, disparity, relative size, texture,  structure
              from motion, and shading.  The majority of the  experiments will involve
              computer-generated displays.  Some  experiments invo lving real scenes will
              also be conducted.    This will be the first comprehensive study of the
              integration of  visual information at multiple levels for the perception of the
               three-dimensional environment.  An understanding of the  perception of objects
              in three-dimensional scenes is important in  any situation in which an observer
              moves through a scene or must  recognize or manipulate objects in a scene.  For
              this reason  there is a close relationship between basic research on human 
              visual perception in dynamic scenes and technological  developments involving
              both human and artificial visual systems,  ranging from improving visual
              displays for the training of pilots  in flight simulators to developing more
              effective robotic visual  systems.    ***
