Title       : Fault Tolerance in System Architectures Implementing the Compression,
               Transmission and Expansion of Data
Type        : Award
NSF Org     : CCR 
Latest
Amendment
Date        : April 26,  2002     
File        : a0104851

Award Number: 0104851
Award Instr.: Continuing grant                             
Prgm Manager: Peter J. Varman                         
	      CCR  DIV OF COMPUTER-COMMUNICATIONS RESEARCH 
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : September 1,  2001  
Expires     : August 31,  2003     (Estimated)
Expected
Total Amt.  : $200960             (Estimated)
Investigator: G. Robert Redinbo redinbo@ece.ucdavis.edu  (Principal Investigator current)
Sponsor     : U of Cal Davis
	      OVCR/Sponsored Programs
	      Davis, CA  956168671    530/752-2075

NSF Program : 4715      COMPUTER SYSTEMS ARCHITECTURE
Fld Applictn: 
Program Ref : 9215,HPCC,
Abstract    :
              Data compression techniques that are important in modern efficient communication
              and storage systems are implemented using computer system architectures with
              multiple processing elements. Computer failure errors reduce the reliability of
              many parts of the overall system because compression is achieved by
reducing
              the residual redundancy common to all forms of data, particularly image
              representations. Also, the resulting formats are extremely sensitive to errors
              introduced by the communications or storage medium. This susceptibility to
              errors has long been known and most international data compression standards
              include resilience features designed to eliminate or mitigate channel error
              effects. Error control coding is employed
in conveying the compressed data.
              However, there are quite different classes of errors emanating from failures in
              the computing resources that implement the compressing, transmitting and
              expanding of the data. The impact of such computational failures can be
              disastrous to critical data in remote-sensing or medical applications that
              depend on compressed data. Hence, fault tolerance capabilities need to be
              considered in system
architectures realizing the compression systems.

The
              proposed research will introduce fault tolerance design methods in data
              compression computing architectures so that temporary computer failures are
              detected, guaranteeing that no corrupted compressed data reaches the intended
              user without warning or appropriate action. The research will analyze the
              specialized effects of computer failure errors in supporting system parts and
              will provide design methodologies to integrate fault tolerance in standard data
              compression algorithms. Protection levels will
be verified by computer
              simulations of the proposed architectural designs. The ultimate goal of this
              research is to influence optional features in data compression standards that
              insure fault tolerance capabilities for critical applications.

Common
              aspects of various compression standards will be studied concerning computer
              failure errors. The work will begin with still image standards and later expand
              to those for video images where motion is involved. Fast transform algorithms,
              integral to many standards, are highly susceptible to even a single
              computational error, and special design techniques are required to avoid
              overwhelming any protection methods applied to them.  Most compression
              standards rely on lossless coding techniques such as Huffman or
arithmetic
              coding. The outputs from these coding steps contain very little redundancy from
              which failure errors can be detected. The prediction methods for compressing
              motion data have feedback paths that greatly exacerbate computer-induced
              errors, and fault tolerance design techniques will need to be developed
              especially for them.  Any fault tolerance design procedures must also be
              integrated with the limited error control features and resilience capabilities
              already present for combating communication or storage
errors, even though
              they address a totally different class of effects.

