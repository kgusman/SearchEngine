Title       : SOFTWARE: Compiler Techniques for High-Performance Computing in Java
Type        : Award
NSF Org     : ACI 
Latest
Amendment
Date        : February 12,  2003  
File        : a0234345

Award Number: 0234345
Award Instr.: Continuing grant                             
Prgm Manager: Xiaodong Zhang                          
	      ACI  DIV OF ADVANCED COMPUT INFRA & RESEARCH 
	      CSE  DIRECT FOR COMPUTER & INFO SCIE & ENGINR
Start Date  : February 1,  2003   
Expires     : January 31,  2006    (Estimated)
Expected
Total Amt.  : $320000             (Estimated)
Investigator: Ken W. Kennedy ken@rice.edu  (Principal Investigator current)
              Zoran Budimlic  (Co-Principal Investigator current)
Sponsor     : William Marsh Rice Univ
	      6100 Main Street, MS-16
	      Houston, TX  772511892    713/348-4820

NSF Program : 4080      ADVANCED COMP RESEARCH PROGRAM
Fld Applictn: 0000099   Other Applications NEC                  
Program Ref : 9216,HPCC,
Abstract    :
              Since its debut in 1995, Java has gained acceptance rapidly among software
              developers as the language of choice for many applications where portability
              and reliability are paramount. Java's support for clean object-oriented (OO)
              design, write once, run anywhere portability, comprehensive static type
              checking, automatic storage management, and safe execution semantics have
              dramatically improved programmer productivity and software
              reliability.
Despite of this high level of interest, Java has made little
              headway in the arena of high-performance
computing because it is too slow. The
              performance penalty is particularly acute when Java programs are written in a
              clean, object-oriented style that makes extensive use of polymorphism. Our
              recent studies of Java performance show that applications written in this
              object-oriented style incur performance penalties of a factor of ten or more
              over applications coded in a more tedious style similar to Fortran and C. If
              this performance gap cannot be bridged, the object-oriented benefits of Java
              will not be realized for compute-intensive applications, squandering an
              opportunity to revolutionize high-performance programming.
We propose to
              address this problem by conducting research into compiler technologies that
              make
it possible to develop applications and component libraries using the
              full power of the Java language
without sacrificing significant run-time
              performance. Although these strategies are suitable for use
in a compiler, we
              will incorporate the resulting technologies into a source-to-source
              optimization
tool. This tool will use application developer interaction to
              help optimize and package the Java
software.
We believe that the development
              of Java implementation technology suitable for high-performance
software could
              catalyze a revolution in the way compute-intensive applications are
              constructed
enabling the solution of more difficult scientific problems and
              the development of web applications
that have heretofore been out of reach. A
              large number of computational scientists share this vision, as evidenced by the
              experimental use of Java reported in the Java Grande Forum.
The optimization
              of object-oriented programs has been an active area of programming
              language
research for nearly twenty years, but little attention has been
              focused on the optimization technology required for high-performance numerical
              computation. Prior to Java, type-safe object-oriented languages were not
              considered candidates for numerical applications. To achieve high performance
              for polymorphic numerical code, the language implementation must perform class
              specialization, which clones a type-specific version of a class containing
              polymorphic fields, object inlining, which replaces a variable containing a
              reference to an object by a tuple of variables containing the object's fields
              and method inlining, which replaces method calls by specialized versions of the
              correspondingmethod body.
We believe that a judicious application of these
              three transformations combined
with standard instruction-level code
              optimization can translate polymorphic object-oriented source
programs to
              machine code comparable in quality to optimized Fortran.
In addition to these
              necessary optimizations, we propose two novel compilation strategies:
              almostwhole-program compilation, which relaxes the above optimizations'
              requirement of whole-program compilation to allow for more programming
              flexibility, and semantics modifying transformations which improve the
              communication between the compiler and the programmer to allow for even more
              aggressive optimizations.
We also propose to apply the technologies resulting
              from this research to optimize several scientific applications written in Java.
